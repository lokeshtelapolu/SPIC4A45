1. SVM
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.metrics import r2_score

# Load dataset
file_path = "/content/customer_demand_analysis_modified.csv"
df = pd.read_csv(file_path)

# Define features and target
X = df[['Marketing_Spend', 'Sales_Quantity', 'Competitor_Price']]
y = df['High_Demand']

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Perform 20 iterations
r2_scores = []
for iteration in range(20):
    # Split into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=iteration)

    # Train Support Vector Machine model
    model = SVR(kernel='rbf')
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Evaluate model using R-squared (Accuracy)
    r2 = r2_score(y_test, y_pred)
    r2_scores.append(r2)
    print(f'Iteration {iteration + 1} - R-squared (Accuracy): {r2:.2f}')

# Print all R-squared values
print("\nAll R-squared Values:")
for i, r2 in enumerate(r2_scores):
    print(f"Iteration {i + 1}: {r2:.2f}")

# Calculate and print the average R-squared
average_r2 = sum(r2_scores) / len(r2_scores)
print(f"\nAverage R-squared across 20 iterations: {average_r2:.2f}")

Iteration 1 - R-squared (Accuracy): 0.86
Iteration 2 - R-squared (Accuracy): 0.87
Iteration 3 - R-squared (Accuracy): 0.86
Iteration 4 - R-squared (Accuracy): 0.87
Iteration 5 - R-squared (Accuracy): 0.89
Iteration 6 - R-squared (Accuracy): 0.88
Iteration 7 - R-squared (Accuracy): 0.85
Iteration 8 - R-squared (Accuracy): 0.87
Iteration 9 - R-squared (Accuracy): 0.87
Iteration 10 - R-squared (Accuracy): 0.87
Iteration 11 - R-squared (Accuracy): 0.88
Iteration 12 - R-squared (Accuracy): 0.90
Iteration 13 - R-squared (Accuracy): 0.90
Iteration 14 - R-squared (Accuracy): 0.86
Iteration 15 - R-squared (Accuracy): 0.86
Iteration 16 - R-squared (Accuracy): 0.85
Iteration 17 - R-squared (Accuracy): 0.88
Iteration 18 - R-squared (Accuracy): 0.87
Iteration 19 - R-squared (Accuracy): 0.89
Iteration 20 - R-squared (Accuracy): 0.83
Average R-squared across 20 iterations: 0.87

2.ExtraTreesClassifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.metrics import accuracy_score

# Load dataset
file_path = "/content/customer_demand_analysis_modified.csv"
df = pd.read_csv(file_path)

# Assuming 'High_Demand' is the target variable
target_column = 'High_Demand'

# Features and target variable
X = df.drop(target_column, axis=1)
y = df[target_column]

# Handle categorical variables using label encoding
label_encoder = LabelEncoder()
X_encoded = X.apply(label_encoder.fit_transform)

# Standardize the data
scaler = StandardScaler()

# Perform 20 iterations
accuracies = []

for iteration in range(20):
    # Split dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=iteration, stratify=y)

    # Standardize the data
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Create an Extra Trees Classifier with optimized parameters for ~75% accuracy
    et_model = ExtraTreesClassifier(
        n_estimators=10,        # Fewer trees to prevent overfitting
        max_depth=5,            # Control depth for generalization
        min_samples_split=300,   # Require at least 300 samples per split
        min_samples_leaf=10,     # At least 10 samples per leaf to prevent deep trees
        max_features="sqrt",     # Limit the number of features per tree
        random_state=iteration
    )
    et_model.fit(X_train_scaled, y_train)

    # Predictions on the test set
    et_predictions = et_model.predict(X_test_scaled)

    # Evaluate model performance
    accuracy = accuracy_score(y_test, et_predictions)
    accuracies.append(accuracy)

    print(f"Iteration {iteration + 1} - Accuracy: {accuracy:.4f}")

# Print all accuracy values
print("\nAll Accuracy Values:")
for i, acc in enumerate(accuracies):
    print(f"Iteration {i + 1}: {acc:.4f}")

# Calculate and print the average accuracy
average_accuracy = sum(accuracies) / len(accuracies)
print(f"\nAverage Accuracy across 20 iterations: {average_accuracy:.4f}")

All Accuracy Values:
Iteration 1: 0.8900
Iteration 2: 0.8500
Iteration 3: 0.8050
Iteration 4: 0.7650
Iteration 5: 0.9400
Iteration 6: 0.8550
Iteration 7: 0.8250
Iteration 8: 0.8200
Iteration 9: 0.8150
Iteration 10: 0.8100
Iteration 11: 0.8400
Iteration 12: 0.9700
Iteration 13: 0.7550
Iteration 14: 0.8850
Iteration 15: 0.8400
Iteration 16: 0.8700
Iteration 17: 0.8700
Iteration 18: 1.0000
Iteration 19: 0.8700
Iteration 20: 0.9700
Average Accuracy across 20 iterations: 0.8623

3.KNN
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load dataset
file_path = "/content/customer_demand_analysis_modified.csv"
df = pd.read_csv(file_path)

# Assuming 'High_Demand' is the target variable
target_column = 'High_Demand'

# Features and target variable
X = df.drop(target_column, axis=1)
y = df[target_column]

# Handle categorical variables using label encoding
label_encoder = LabelEncoder()
X_encoded = X.apply(label_encoder.fit_transform)

# Standardize the data
scaler = StandardScaler()

# Perform 20 iterations
accuracies = []

for iteration in range(20):
    # Split dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=iteration, stratify=y)

    # Standardize the data
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Create a KNN Classifier with optimized parameters for ~75% accuracy
    knn_model = KNeighborsClassifier(
        n_neighbors=2,       # Uses 5 nearest neighbors
        weights='uniform',   # Equal weight for all neighbors
        metric='euclidean'   # Uses Euclidean distance
    )
    knn_model.fit(X_train_scaled, y_train)

    # Predictions on the test set
    knn_predictions = knn_model.predict(X_test_scaled)

    # Evaluate model performance
    accuracy = accuracy_score(y_test, knn_predictions)
    accuracies.append(accuracy)

    print(f"Iteration {iteration + 1} - Accuracy: {accuracy:.4f}")

# Print all accuracy values
print("\nAll Accuracy Values:")
for i, acc in enumerate(accuracies):
    print(f"Iteration {i + 1}: {acc:.4f}")

# Calculate and print the average accuracy
average_accuracy = sum(accuracies) / len(accuracies)
print(f"\nAverage Accuracy across 20 iterations: {average_accuracy:.4f}")

All Accuracy Values:
Iteration 1: 0.7500
Iteration 2: 0.7700
Iteration 3: 0.7800
Iteration 4: 0.8000
Iteration 5: 0.7550
Iteration 6: 0.7250
Iteration 7: 0.7550
Iteration 8: 0.6950
Iteration 9: 0.7750
Iteration 10: 0.7100
Iteration 11: 0.7600
Iteration 12: 0.7700
Iteration 13: 0.7600
Iteration 14: 0.7850
Iteration 15: 0.7350
Iteration 16: 0.7400
Iteration 17: 0.7100
Iteration 18: 0.7850
Iteration 19: 0.7700
Iteration 20: 0.7300
Average Accuracy across 20 iterations: 0.7530

4.RANDOM FOREST
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score

# Load dataset
file_path = "/content/customer_demand_analysis_modified.csv"
df = pd.read_csv(file_path)

# Define features and target
X = df[['Marketing_Spend', 'Sales_Quantity', 'Competitor_Price','Discount']]
y = df['Price']

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Perform 20 iterations
r2_scores = []
for iteration in range(20):
    # Split into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=iteration)

    # Train Random Forest model
    model = RandomForestRegressor(n_estimators=100, random_state=iteration)
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Evaluate model using R-squared (Accuracy)
    r2 = r2_score(y_test, y_pred)
    r2_scores.append(r2)
    print(f'Iteration {iteration + 1} - R-squared (Accuracy): {r2:.2f}')

# Print all R-squared values
print("\nAll R-squared Values:")
for i, r2 in enumerate(r2_scores):
    print(f"Iteration {i + 1}: {r2:.2f}")

# Calculate and print the average R-squared
average_r2 = sum(r2_scores) / len(r2_scores)
print(f"\nAverage R-squared across 20 iterations: {average_r2:.2f}")

All R-squared Values:
Iteration 1: 0.95
Iteration 2: 0.96
Iteration 3: 0.95
Iteration 4: 0.96
Iteration 5: 0.95
Iteration 6: 0.95
Iteration 7: 0.95
Iteration 8: 0.95
Iteration 9: 0.95
Iteration 10: 0.96
Iteration 11: 0.95
Iteration 12: 0.95
Iteration 13: 0.96
Iteration 14: 0.95
Iteration 15: 0.95
Iteration 16: 0.95
Iteration 17: 0.95
Iteration 18: 0.95
Iteration 19: 0.95
Iteration 20: 0.95

Average R-squared across 20 iterations: 0.95  (Some Changes Accuracy Values Randomly give 90.80)

5. XG BOOST BASE ALGORITHM
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import r2_score

# Load dataset
file_path = "/content/customer_demand_analysis_modified.csv"
df = pd.read_csv(file_path)

# Define features and target
X = df[['Marketing_Spend', 'Competitor_Price']]
y = df['Price']

# Perform 20 iterations
r2_scores = []

for iteration in range(20):
    # Split into train and test sets with different random states
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=iteration)

    # Train XGBoost model
    model = XGBRegressor()
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Evaluate model using R-squared
    r2 = r2_score(y_test, y_pred)
    r2_scores.append(r2)

    print(f"Iteration {iteration + 1} - R-squared (Accuracy): {r2:.4f}")

# Print all R² values
print("\nAll R² Values:")
for i, score in enumerate(r2_scores):
    print(f"Iteration {i + 1}: {score:.4f}")

# Calculate and print the average R² score
average_r2 = np.mean(r2_scores)
print(f"\nAverage R-squared across 20 iterations: {average_r2:.4f}")

All R² Values:
Iteration 1: 0.9363
Iteration 2: 0.9509
Iteration 3: 0.9460
Iteration 4: 0.9451
Iteration 5: 0.9413
Iteration 6: 0.9293
Iteration 7: 0.9347
Iteration 8: 0.9327
Iteration 9: 0.9466
Iteration 10: 0.9454
Iteration 11: 0.9316
Iteration 12: 0.9230
Iteration 13: 0.9457
Iteration 14: 0.9263
Iteration 15: 0.9328
Iteration 16: 0.9332
Iteration 17: 0.9440
Iteration 18: 0.9331
Iteration 19: 0.9350
Iteration 20: 0.9304

Average R-squared across 20 iterations: 0.9372
