1.ExtraTreesClassifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE
import warnings
import numpy as np

# Suppress warnings
warnings.filterwarnings("ignore")

# Load dataset
df = pd.read_csv("/content/lokesh dataset.csv")

# Preprocess data
target = 'Member'
X = df.drop(columns=[target, 'Created On'])
y = LabelEncoder().fit_transform(df[target])
X['Description'] = LabelEncoder().fit_transform(X['Description'])

# Store accuracies
etc_accuracies = []
gbm_accuracies = []

# Run 10 iterations
for i in range(1, 11):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)
    X_train, y_train = SMOTE(random_state=None).fit_resample(X_train, y_train)
    scaler = StandardScaler()
    X_train[['Order', 'SKU']] = scaler.fit_transform(X_train[['Order', 'SKU']])
    X_test[['Order', 'SKU']] = scaler.transform(X_test[['Order', 'SKU']])

    # Train models
    etc_model = ExtraTreesClassifier(n_estimators=200, max_depth=10, random_state=None)
    etc_model.fit(X_train, y_train)
    gbm_model = GradientBoostingClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, random_state=None)
    gbm_model.fit(X_train, y_train)

    # Store accuracies
    etc_acc = accuracy_score(y_test, etc_model.predict(X_test)) * 100
    gbm_acc = accuracy_score(y_test, gbm_model.predict(X_test)) * 100
    etc_accuracies.append(etc_acc)
    gbm_accuracies.append(gbm_acc)

    # Print iteration-wise accuracy
    print(f"Iteration {i}: Extra Trees Accuracy: {etc_acc:.2f}% | GBM Accuracy: {gbm_acc:.2f}%")

# Print final summary
print("Final Extra Trees Accuracies:", np.round(etc_accuracies, 2))
print("Final GBM Accuracies:", np.round(gbm_accuracies, 2))

Iteration 1: Extra Trees Accuracy: 55.94% | GBM Accuracy: 96.27%
Iteration 2: Extra Trees Accuracy: 53.15% | GBM Accuracy: 95.34%
Iteration 3: Extra Trees Accuracy: 51.75% | GBM Accuracy: 95.10%
Iteration 4: Extra Trees Accuracy: 53.61% | GBM Accuracy: 95.80%
Iteration 5: Extra Trees Accuracy: 48.25% | GBM Accuracy: 95.57%
Iteration 6: Extra Trees Accuracy: 51.98% | GBM Accuracy: 93.47%
Iteration 7: Extra Trees Accuracy: 52.91% | GBM Accuracy: 96.97%
Iteration 8: Extra Trees Accuracy: 51.28% | GBM Accuracy: 92.77%
Iteration 9: Extra Trees Accuracy: 54.55% | GBM Accuracy: 93.94%
Iteration 10: Extra Trees Accuracy: 51.28% | GBM Accuracy: 95.80%
Final Extra Trees Accuracies: [55.94 53.15 51.75 53.61 48.25 51.98 52.91 51.28 54.55 51.28]
Final GBM Accuracies: [96.27 95.34 95.1  95.8  95.57 93.47 96.97 92.77 93.94 95.8 ]

2.DecisionTreeClassifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE
import warnings
import numpy as np

# Suppress warnings
warnings.filterwarnings("ignore")

# Load dataset
df = pd.read_csv("/content/lokesh dataset.csv")

# Preprocess data
target = 'Member'
X = df.drop(columns=[target, 'Created On'])
y = LabelEncoder().fit_transform(df[target])
X['Description'] = LabelEncoder().fit_transform(X['Description'])

# Store accuracies
dt_accuracies = []
gbm_accuracies = []

# Run 10 iterations
for i in range(1, 11):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)
    X_train, y_train = SMOTE(random_state=None).fit_resample(X_train, y_train)
    scaler = StandardScaler()
    X_train[['Order', 'SKU']] = scaler.fit_transform(X_train[['Order', 'SKU']])
    X_test[['Order', 'SKU']] = scaler.transform(X_test[['Order', 'SKU']])

    # Train models
    dt_model = DecisionTreeClassifier(max_depth=8, random_state=None)
    dt_model.fit(X_train, y_train)
    gbm_model = GradientBoostingClassifier(n_estimators=30, max_depth=8, learning_rate=0.05, random_state=None)
    gbm_model.fit(X_train, y_train)

    # Store accuracies
    dt_acc = accuracy_score(y_test, dt_model.predict(X_test)) * 100
    gbm_acc = accuracy_score(y_test, gbm_model.predict(X_test)) * 100
    dt_accuracies.append(dt_acc)
    gbm_accuracies.append(gbm_acc)

    # Print iteration-wise accuracy
    print(f"Iteration {i}: Decision Tree Accuracy: {dt_acc:.2f}% | GBM Accuracy: {gbm_acc:.2f}%")

# Print final summary
print("Final Decision Tree Accuracies:", np.round(dt_accuracies, 2))
print("Final GBM Accuracies:", np.round(gbm_accuracies, 2))

Iteration 1: Decision Tree Accuracy: 55.71% | GBM Accuracy: 81.82%
Iteration 2: Decision Tree Accuracy: 55.94% | GBM Accuracy: 82.98%
Iteration 3: Decision Tree Accuracy: 55.48% | GBM Accuracy: 83.92%
Iteration 4: Decision Tree Accuracy: 55.24% | GBM Accuracy: 83.68%
Iteration 5: Decision Tree Accuracy: 51.52% | GBM Accuracy: 82.52%
Iteration 6: Decision Tree Accuracy: 56.41% | GBM Accuracy: 84.85%
Iteration 7: Decision Tree Accuracy: 59.91% | GBM Accuracy: 86.01%
Iteration 8: Decision Tree Accuracy: 60.14% | GBM Accuracy: 81.35%
Iteration 9: Decision Tree Accuracy: 51.05% | GBM Accuracy: 84.15%
Iteration 10: Decision Tree Accuracy: 49.88% | GBM Accuracy: 78.79%
Final Decision Tree Accuracies: [55.71 55.94 55.48 55.24 51.52 56.41 59.91 60.14 51.05 49.88]
Final GBM Accuracies: [81.82 82.98 83.92 83.68 82.52 84.85 86.01 81.35 84.15 78.79]

3.RandomForestClassifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE
import warnings
import numpy as np

# Suppress warnings
warnings.filterwarnings("ignore")

# Load dataset
df = pd.read_csv("/content/lokesh dataset.csv")

# Preprocess data
target = 'Member'
X = df.drop(columns=[target, 'Created On'])
y = LabelEncoder().fit_transform(df[target])
X['Description'] = LabelEncoder().fit_transform(X['Description'])

# Store accuracies
rf_accuracies = []
gbm_accuracies = []

# Run 10 iterations
for i in range(1, 11):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)
    X_train, y_train = SMOTE(random_state=None).fit_resample(X_train, y_train)
    scaler = StandardScaler()
    X_train[['Order', 'SKU']] = scaler.fit_transform(X_train[['Order', 'SKU']])
    X_test[['Order', 'SKU']] = scaler.transform(X_test[['Order', 'SKU']])

    # Train models
    rf_model = RandomForestClassifier(n_estimators=8000, max_depth=8, random_state=None)
    rf_model.fit(X_train, y_train)
    gbm_model = GradientBoostingClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, random_state=None)
    gbm_model.fit(X_train, y_train)

    # Store accuracies
    rf_acc = accuracy_score(y_test, rf_model.predict(X_test)) * 100
    gbm_acc = accuracy_score(y_test, gbm_model.predict(X_test)) * 100
    rf_accuracies.append(rf_acc)
    gbm_accuracies.append(gbm_acc)

    # Print iteration-wise accuracy
    print(f"Iteration {i}: Random Forest Accuracy: {rf_acc:.2f}% | GBM Accuracy: {gbm_acc:.2f}%")

# Print final summary
print("Final Random Forest Accuracies:", np.round(rf_accuracies, 2))
print("Final GBM Accuracies:", np.round(gbm_accuracies, 2))

Iteration 1: Random Forest Accuracy: 56.88% | GBM Accuracy: 93.24%
Iteration 2: Random Forest Accuracy: 51.98% | GBM Accuracy: 96.27%
Iteration 3: Random Forest Accuracy: 58.74% | GBM Accuracy: 95.34%
Iteration 4: Random Forest Accuracy: 58.28% | GBM Accuracy: 94.64%
Iteration 5: Random Forest Accuracy: 54.78% | GBM Accuracy: 95.34%
Iteration 6: Random Forest Accuracy: 55.94% | GBM Accuracy: 96.50%
Iteration 7: Random Forest Accuracy: 56.18% | GBM Accuracy: 95.80%
Iteration 8: Random Forest Accuracy: 53.61% | GBM Accuracy: 95.34%
Iteration 9: Random Forest Accuracy: 56.18% | GBM Accuracy: 94.17%
Iteration 10: Random Forest Accuracy: 55.01% | GBM Accuracy: 92.54%
Final Random Forest Accuracies: [56.88 51.98 58.74 58.28 54.78 55.94 56.18 53.61 56.18 55.01]
Final GBM Accuracies: [93.24 96.27 95.34 94.64 95.34 96.5  95.8  95.34 94.17 92.54]

4.XGBClassifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from xgboost import XGBClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE
import warnings
import numpy as np

# Suppress warnings
warnings.filterwarnings("ignore")

# Load dataset
df = pd.read_csv("/content/lokesh dataset.csv")

# Preprocess data
target = 'Member'
X = df.drop(columns=[target, 'Created On'])
y = LabelEncoder().fit_transform(df[target])
X['Description'] = LabelEncoder().fit_transform(X['Description'])

# Store accuracies
xgb_accuracies = []
gbm_accuracies = []

# Run 10 iterations
for i in range(1, 11):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)
    X_train, y_train = SMOTE(random_state=None).fit_resample(X_train, y_train)
    scaler = StandardScaler()
    X_train[['Order', 'SKU']] = scaler.fit_transform(X_train[['Order', 'SKU']])
    X_test[['Order', 'SKU']] = scaler.transform(X_test[['Order', 'SKU']])

    # Train models
    xgb_model = XGBClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, subsample=0.9, colsample_bytree=0.8, random_state=None, verbosity=0)
    xgb_model.fit(X_train, y_train)
    gbm_model = GradientBoostingClassifier(n_estimators=300, max_depth=8, learning_rate=0.05, random_state=None)
    gbm_model.fit(X_train, y_train)

    # Store accuracies
    xgb_acc = accuracy_score(y_test, xgb_model.predict(X_test)) * 100
    gbm_acc = accuracy_score(y_test, gbm_model.predict(X_test)) * 100
    xgb_accuracies.append(xgb_acc)
    gbm_accuracies.append(gbm_acc)

    # Print iteration-wise accuracy
    print(f"Iteration {i}: XGBoost Accuracy: {xgb_acc:.2f}% | GBM Accuracy: {gbm_acc:.2f}%")

# Print final summary
print("Final XGBoost Accuracies:", np.round(xgb_accuracies, 2))
print("Final GBM Accuracies:", np.round(gbm_accuracies, 2))

Iteration 1: XGBoost Accuracy: 88.34% | GBM Accuracy: 94.87%
Iteration 2: XGBoost Accuracy: 89.51% | GBM Accuracy: 94.41%
Iteration 3: XGBoost Accuracy: 87.65% | GBM Accuracy: 94.87%
Iteration 4: XGBoost Accuracy: 87.88% | GBM Accuracy: 95.34%
Iteration 5: XGBoost Accuracy: 90.44% | GBM Accuracy: 97.20%
Iteration 6: XGBoost Accuracy: 88.58% | GBM Accuracy: 96.04%
Iteration 7: XGBoost Accuracy: 89.28% | GBM Accuracy: 95.34%
Iteration 8: XGBoost Accuracy: 86.95% | GBM Accuracy: 95.34%
Iteration 9: XGBoost Accuracy: 86.95% | GBM Accuracy: 94.41%
Iteration 10: XGBoost Accuracy: 89.51% | GBM Accuracy: 94.64%
Final XGBoost Accuracies: [88.34 89.51 87.65 87.88 90.44 88.58 89.28 86.95 86.95 89.51]
Final GBM Accuracies: [94.87 94.41 94.87 95.34 97.2  96.04 95.34 95.34 94.41 94.64]
